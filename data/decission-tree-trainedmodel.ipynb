{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b25af37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Head:\n",
      "  student id  dost_exam_result  filipino grade  English grade  \\\n",
      "0  student 1                 0              89             90   \n",
      "1  student 2                 0              89             79   \n",
      "2  student 3                 0              84             90   \n",
      "3  student 4                 0              87             90   \n",
      "4  student 5                 0              82             90   \n",
      "\n",
      "   mathematics grade  science grade  araling panlipunan grade  \\\n",
      "0                 78             86                        87   \n",
      "1                 89             81                        79   \n",
      "2                 79             90                        88   \n",
      "3                 79             87                        79   \n",
      "4                 82             75                        80   \n",
      "\n",
      "   Edukasyon sa pagpapakatao grade  \\\n",
      "0                               83   \n",
      "1                               82   \n",
      "2                               90   \n",
      "3                               83   \n",
      "4                               84   \n",
      "\n",
      "   Edukasyong panglipunan at pangkabuhayan grade  MAPEH grade  Average grade  \\\n",
      "0                                             90           75             75   \n",
      "1                                             85           76             82   \n",
      "2                                             84           84             83   \n",
      "3                                             90           77             80   \n",
      "4                                             83           81             81   \n",
      "\n",
      "   hetero  top 5  ste  spfl  sptve  \n",
      "0       1      0    0     0      0  \n",
      "1       1      0    0     0      0  \n",
      "2       1      0    0     0      0  \n",
      "3       1      0    0     0      0  \n",
      "4       1      0    0     0      0  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 680 entries, 0 to 679\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                         Non-Null Count  Dtype \n",
      "---  ------                                         --------------  ----- \n",
      " 0   student id                                     680 non-null    object\n",
      " 1   dost_exam_result                               680 non-null    int64 \n",
      " 2   filipino grade                                 680 non-null    int64 \n",
      " 3   English grade                                  680 non-null    int64 \n",
      " 4   mathematics grade                              680 non-null    int64 \n",
      " 5   science grade                                  680 non-null    int64 \n",
      " 6   araling panlipunan grade                       680 non-null    int64 \n",
      " 7   Edukasyon sa pagpapakatao grade                680 non-null    int64 \n",
      " 8   Edukasyong panglipunan at pangkabuhayan grade  680 non-null    int64 \n",
      " 9   MAPEH grade                                    680 non-null    int64 \n",
      " 10  Average grade                                  680 non-null    int64 \n",
      " 11  hetero                                         680 non-null    int64 \n",
      " 12  top 5                                          680 non-null    int64 \n",
      " 13  ste                                            680 non-null    int64 \n",
      " 14  spfl                                           680 non-null    int64 \n",
      " 15  sptve                                          680 non-null    int64 \n",
      "dtypes: int64(15), object(1)\n",
      "memory usage: 85.1+ KB\n"
     ]
    }
   ],
   "source": [
    "    # Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "import numpy as np\n",
    "\n",
    "    # Load the dataset\n",
    "    # IMPORTANT: Update this file_path to your exact CSV file location\n",
    "file_path = 'data_program_recommendation - Copy (tryy1).csv'\n",
    "    # The 'r' before the string makes it a \"raw string\", which handles backslashes correctly in Windows paths.\n",
    "    # Alternatively, you can use forward slashes:\n",
    "    # file_path = 'C:/Users/Marwina/Desktop/Anacondas/2025-CP_Section_Placement_and_Student_Risk_Prediction/data/MultipleFiles/data_program_recommendation - Copy (tryy1).csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the first few rows of the dataframe to understand its structure\n",
    "print(\"Original DataFrame Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2b30fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Features (X) Head:\n",
      "   dost_exam_result  filipino grade  English grade  mathematics grade  \\\n",
      "0                 0              89             90                 78   \n",
      "1                 0              89             79                 89   \n",
      "2                 0              84             90                 79   \n",
      "3                 0              87             90                 79   \n",
      "4                 0              82             90                 82   \n",
      "\n",
      "   science grade  araling panlipunan grade  Edukasyon sa pagpapakatao grade  \\\n",
      "0             86                        87                               83   \n",
      "1             81                        79                               82   \n",
      "2             90                        88                               90   \n",
      "3             87                        79                               83   \n",
      "4             75                        80                               84   \n",
      "\n",
      "   Edukasyong panglipunan at pangkabuhayan grade  MAPEH grade  Average grade  \n",
      "0                                             90           75             75  \n",
      "1                                             85           76             82  \n",
      "2                                             84           84             83  \n",
      "3                                             90           77             80  \n",
      "4                                             83           81             81  \n",
      "\n",
      "Output Labels (y) Head:\n",
      "   hetero  top 5  ste  spfl  sptve\n",
      "0       1      0    0     0      0\n",
      "1       1      0    0     0      0\n",
      "2       1      0    0     0      0\n",
      "3       1      0    0     0      0\n",
      "4       1      0    0     0      0\n"
     ]
    }
   ],
   "source": [
    "    # Define input features (X) and output labels (y)\n",
    "\n",
    "    # Input features are the grades and exam results\n",
    "    # We exclude 'student id' as it's just an identifier and 'dost_exam_result'\n",
    "    # if it's considered part of the input criteria rather than a direct grade.\n",
    "    # Assuming 'dost_exam_result' is an input feature (0 or 1 indicating pass/fail or participation)\n",
    "    # and not a grade, we'll include it.\n",
    "    # The grades are from 'filipino grade' to 'Average grade'.\n",
    "    # 'hetero', 'top 5', 'ste', 'spfl', 'sptve' are our target labels.\n",
    "\n",
    "X = df[['dost_exam_result', 'filipino grade', 'English grade', 'mathematics grade',\n",
    "            'science grade', 'araling panlipunan grade', 'Edukasyon sa pagpapakatao grade',\n",
    "            'Edukasyong panglipunan at pangkabuhayan grade', 'MAPEH grade', 'Average grade']]\n",
    "\n",
    "    # Output labels are the program eligibility columns\n",
    "y = df[['hetero', 'top 5', 'ste', 'spfl', 'sptve']]\n",
    "\n",
    "print(\"\\nInput Features (X) Head:\")\n",
    "print(X.head())\n",
    "print(\"\\nOutput Labels (y) Head:\")\n",
    "print(y.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd0d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 544 samples\n",
      "Testing set size: 136 samples\n"
     ]
    }
   ],
   "source": [
    "    # Split the data into training and testing sets (80% train, 20% test)\n",
    "    # random_state ensures reproducibility of the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)} samples\")\n",
    "print(f\"Testing set size: {len(X_test)} samples\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf20fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for: hetero\n",
      "Accuracy for hetero: 1.0000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'top 5'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Combine individual predictions into a single array for overall evaluation\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# This creates a 2D array where each row is a student's predictions across all labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m overall_predictions = np.array([\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y.columns]).T\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSample of combined predictions (first 5 students):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(overall_predictions[:\u001b[32m5\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'top 5'"
     ]
    }
   ],
   "source": [
    "    # Initialize a dictionary to store trained models for each label\n",
    "models = {}\n",
    "predictions = {}\n",
    "overall_predictions = []\n",
    "\n",
    "    # Train a Decision Tree Classifier for each program eligibility label\n",
    "for label in y.columns:\n",
    "    print(f\"\\nTraining model for: {label}\")\n",
    "        # Create a Decision Tree Classifier instance\n",
    "        # You can tune hyperparameters like max_depth, min_samples_leaf, etc.\n",
    "        # For now, we'll use default settings.\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the training data for the current label\n",
    "    model.fit(X_train, y_train[label])\n",
    "\n",
    "        # Store the trained model\n",
    "    models[label] = model\n",
    "\n",
    "        # Make predictions on the test set for the current label\n",
    "    y_pred_label = model.predict(X_test)\n",
    "    predictions[label] = y_pred_label\n",
    "\n",
    "        # Print accuracy for the current label\n",
    "    accuracy = accuracy_score(y_test[label], y_pred_label)\n",
    "    print(f\"Accuracy for {label}: {accuracy:.4f}\")\n",
    "\n",
    "    # Combine individual predictions into a single array for overall evaluation\n",
    "    # This creates a 2D array where each row is a student's predictions across all labels\n",
    "    overall_predictions = np.array([predictions[label] for label in y.columns]).T\n",
    "\n",
    "    print(\"\\nSample of combined predictions (first 5 students):\")\n",
    "    print(overall_predictions[:5])\n",
    "    print(\"\\nSample of actual labels (first 5 students):\")\n",
    "    print(y_test.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255968d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing label: hetero ---\n",
      "Model for hetero trained and stored.\n",
      "Predictions for hetero made and stored.\n",
      "Accuracy for hetero: 1.0000\n",
      "\n",
      "--- Processing label: top 5 ---\n",
      "Model for top 5 trained and stored.\n",
      "Predictions for top 5 made and stored.\n",
      "Accuracy for top 5: 0.9926\n",
      "\n",
      "--- Processing label: ste ---\n",
      "Model for ste trained and stored.\n",
      "Predictions for ste made and stored.\n",
      "Accuracy for ste: 1.0000\n",
      "\n",
      "--- Processing label: spfl ---\n",
      "Model for spfl trained and stored.\n",
      "Predictions for spfl made and stored.\n",
      "Accuracy for spfl: 1.0000\n",
      "\n",
      "--- Processing label: sptve ---\n",
      "Model for sptve trained and stored.\n",
      "Predictions for sptve made and stored.\n",
      "Accuracy for sptve: 1.0000\n",
      "\n",
      "--- Contents of 'predictions' dictionary after loop ---\n",
      "dict_keys(['hetero', 'top 5', 'ste', 'spfl', 'sptve'])\n",
      "\n",
      "Overall predictions successfully combined.\n",
      "\n",
      "Sample of combined predictions (first 5 students):\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 0 0 0 0]\n",
      " [1 1 0 1 1]\n",
      " [1 1 0 0 0]]\n",
      "\n",
      "Sample of actual labels (first 5 students):\n",
      "     hetero  top 5  ste  spfl  sptve\n",
      "647       1      1    1     1      1\n",
      "607       1      1    1     1      1\n",
      "63        1      0    0     0      0\n",
      "319       1      1    0     1      1\n",
      "101       1      1    0     0      0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store trained models for each label\n",
    "models = {}\n",
    "predictions = {}\n",
    "overall_predictions = []\n",
    "\n",
    "# Train a Decision Tree Classifier for each program eligibility label\n",
    "for label in y.columns:\n",
    "    print(f\"\\n--- Processing label: {label} ---\") # Debugging print\n",
    "    try:\n",
    "        # Create a Decision Tree Classifier instance\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the training data for the current label\n",
    "        model.fit(X_train, y_train[label])\n",
    "\n",
    "        # Store the trained model\n",
    "        models[label] = model\n",
    "        print(f\"Model for {label} trained and stored.\") # Debugging print\n",
    "\n",
    "        # Make predictions on the test set for the current label\n",
    "        y_pred_label = model.predict(X_test)\n",
    "        predictions[label] = y_pred_label\n",
    "        print(f\"Predictions for {label} made and stored.\") # Debugging print\n",
    "\n",
    "        # Print accuracy for the current label\n",
    "        accuracy = accuracy_score(y_test[label], y_pred_label)\n",
    "        print(f\"Accuracy for {label}: {accuracy:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing label '{label}': {e}\")\n",
    "        # This will help us see if any specific label causes a problem during training/prediction\n",
    "        continue # Skip to the next label if an error occurs for the current one\n",
    "\n",
    "# After the loop, check what's actually in the 'predictions' dictionary\n",
    "print(\"\\n--- Contents of 'predictions' dictionary after loop ---\")\n",
    "print(predictions.keys()) # This will show which labels successfully had predictions stored\n",
    "\n",
    "# Combine individual predictions into a single array for overall evaluation\n",
    "# This creates a 2D array where each row is a student's predictions across all labels\n",
    "# Ensure all labels in y.columns are present in predictions.keys()\n",
    "try:\n",
    "    overall_predictions = np.array([predictions[label] for label in y.columns]).T\n",
    "    print(\"\\nOverall predictions successfully combined.\")\n",
    "except KeyError as ke:\n",
    "    print(f\"\\nKeyError during overall_predictions combination: {ke}\")\n",
    "    print(\"This means a label in y.columns was not found in the 'predictions' dictionary.\")\n",
    "    print(\"Please check the previous error messages for why that label might have failed.\")\n",
    "    # You might want to exit or handle this more gracefully depending on your needs\n",
    "    # For now, we'll just print the error and stop.\n",
    "    raise # Re-raise the original KeyError to stop execution if it's critical\n",
    "\n",
    "\n",
    "print(\"\\nSample of combined predictions (first 5 students):\")\n",
    "print(overall_predictions[:5])\n",
    "print(\"\\nSample of actual labels (first 5 students):\")\n",
    "print(y_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8a54b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for: hetero\n",
      "Accuracy for hetero: 1.0000\n",
      "\n",
      "Training model for: top 5\n",
      "Accuracy for top 5: 0.9926\n",
      "\n",
      "Training model for: ste\n",
      "Accuracy for ste: 1.0000\n",
      "\n",
      "Training model for: spfl\n",
      "Accuracy for spfl: 1.0000\n",
      "\n",
      "Training model for: sptve\n",
      "Accuracy for sptve: 1.0000\n",
      "\n",
      "Sample of combined predictions (first 5 students):\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 0 0 0 0]\n",
      " [1 1 0 1 1]\n",
      " [1 1 0 0 0]]\n",
      "\n",
      "Sample of actual labels (first 5 students):\n",
      "     hetero  top 5  ste  spfl  sptve\n",
      "647       1      1    1     1      1\n",
      "607       1      1    1     1      1\n",
      "63        1      0    0     0      0\n",
      "319       1      1    0     1      1\n",
      "101       1      1    0     0      0\n"
     ]
    }
   ],
   "source": [
    "    # Initialize a dictionary to store trained models for each label\n",
    "models = {}\n",
    "predictions = {}\n",
    "overall_predictions = []\n",
    "\n",
    "    # Train a Decision Tree Classifier for each program eligibility label\n",
    "for label in y.columns:\n",
    "        print(f\"\\nTraining model for: {label}\")\n",
    "        # Create a Decision Tree Classifier instance\n",
    "        # You can tune hyperparameters like max_depth, min_samples_leaf, etc.\n",
    "        # For now, we'll use default settings.\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Train the model on the training data for the current label\n",
    "        model.fit(X_train, y_train[label])\n",
    "\n",
    "        # Store the trained model\n",
    "        models[label] = model\n",
    "\n",
    "        # Make predictions on the test set for the current label\n",
    "        y_pred_label = model.predict(X_test)\n",
    "        predictions[label] = y_pred_label\n",
    "\n",
    "        # Print accuracy for the current label\n",
    "        accuracy = accuracy_score(y_test[label], y_pred_label)\n",
    "        print(f\"Accuracy for {label}: {accuracy:.4f}\")\n",
    "\n",
    "    # Combine individual predictions into a single array for overall evaluation\n",
    "    # This creates a 2D array where each row is a student's predictions across all labels\n",
    "overall_predictions = np.array([predictions[label] for label in y.columns]).T\n",
    "\n",
    "print(\"\\nSample of combined predictions (first 5 students):\")\n",
    "print(overall_predictions[:5])\n",
    "print(\"\\nSample of actual labels (first 5 students):\")\n",
    "print(y_test.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845869e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Hamming Loss: 0.0015\n",
      "Overall Exact Match Ratio (Subset Accuracy): 0.9926\n"
     ]
    }
   ],
   "source": [
    "    # Evaluate the overall multi-label model performance\n",
    "\n",
    "    # Convert y_test to a NumPy array for consistent comparison\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "    # Hamming Loss: Measures the fraction of labels that are incorrectly predicted.\n",
    "    # Lower Hamming Loss is better.\n",
    "h_loss = hamming_loss(y_test_np, overall_predictions)\n",
    "print(f\"\\nOverall Hamming Loss: {h_loss:.4f}\")\n",
    "\n",
    "    # Exact Match Ratio (Subset Accuracy): The percentage of samples for which\n",
    "    # all labels are correctly predicted.\n",
    "    # Higher Exact Match Ratio is better.\n",
    "exact_match_ratio = np.all(y_test_np == overall_predictions, axis=1).mean()\n",
    "print(f\"Overall Exact Match Ratio (Subset Accuracy): {exact_match_ratio:.4f}\")\n",
    "\n",
    "    # You can also calculate other multi-label metrics like F1-score, Jaccard similarity, etc.\n",
    "    # For simplicity, we'll stick to Hamming Loss and Exact Match Ratio for now.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea33d266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Student Data:\n",
      "   dost_exam_result  filipino grade  English grade  mathematics grade  \\\n",
      "0                 1              90             85                 92   \n",
      "\n",
      "   science grade  araling panlipunan grade  Edukasyon sa pagpapakatao grade  \\\n",
      "0             88                        80                               85   \n",
      "\n",
      "   Edukasyong panglipunan at pangkabuhayan grade  MAPEH grade  Average grade  \n",
      "0                                             90           82             87  \n",
      "\n",
      "Program Recommendations for New Student:\n",
      "- Hetero: Eligible\n",
      "- Top 5: Eligible\n",
      "- Ste: Not Eligible\n",
      "- Spfl: Not Eligible\n",
      "- Sptve: Not Eligible\n"
     ]
    }
   ],
   "source": [
    "    # Example: Make predictions for a new student\n",
    "    # You need to provide the same input features as used for training\n",
    "    # The order of features must be the same:\n",
    "    # ['dost_exam_result', 'filipino grade', 'English grade', 'mathematics grade',\n",
    "    #  'science grade', 'araling panlipunan grade', 'Edukasyon sa pagpapakatao grade',\n",
    "    #  'Edukasyong panglipunan at pangkabuhayan grade', 'MAPEH grade', 'Average grade']\n",
    "\n",
    "    # Example student data:\n",
    "    # dost_exam_result: 1 (passed)\n",
    "    # filipino grade: 90\n",
    "    # English grade: 85\n",
    "    # mathematics grade: 92\n",
    "    # science grade: 88\n",
    "    # araling panlipunan grade: 80\n",
    "    # Edukasyon sa pagpapakatao grade: 85\n",
    "    # Edukasyong panglipunan at pangkabuhayan grade: 90\n",
    "    # MAPEH grade: 82\n",
    "    # Average grade: 87\n",
    "\n",
    "new_student_data = pd.DataFrame([[1, 90, 85, 92, 88, 80, 85, 90, 82, 87]],\n",
    "                                    columns=X.columns)\n",
    "\n",
    "print(\"\\nNew Student Data:\")\n",
    "print(new_student_data)\n",
    "\n",
    "recommended_programs = {}\n",
    "for label, model in models.items():\n",
    "        # Predict for the new student using each trained model\n",
    "        prediction = model.predict(new_student_data)[0] # [0] to get the single prediction value\n",
    "        recommended_programs[label] = \"Eligible\" if prediction == 1 else \"Not Eligible\"\n",
    "\n",
    "print(\"\\nProgram Recommendations for New Student:\")\n",
    "for program, status in recommended_programs.items():\n",
    "        print(f\"- {program.replace('_', ' ').title()}: {status}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a692015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeae9be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Student Data:\n",
      "   dost_exam_result  filipino grade  English grade  mathematics grade  \\\n",
      "0                 1              90             85                 92   \n",
      "\n",
      "   science grade  araling panlipunan grade  Edukasyon sa pagpapakatao grade  \\\n",
      "0             88                        80                               85   \n",
      "\n",
      "   Edukasyong panglipunan at pangkabuhayan grade  MAPEH grade  Average grade  \n",
      "0                                             90           82             87  \n",
      "\n",
      "--- Detailed Program Recommendations and Explanations ---\n",
      "\n",
      "Program: Hetero - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "\n",
      "Program: Top 5 - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (87) led to decision (Average grade > 84.50). Branch: False\n",
      "  - Node 2: Student's 'Edukasyong panglipunan at pangkabuhayan grade' grade (90) led to decision (Edukasyong panglipunan at pangkabuhayan grade > 76.50). Branch: False\n",
      "  - Node 3: Student's 'filipino grade' grade (90) led to decision (filipino grade > 75.50). Branch: False\n",
      "\n",
      "Program: Ste - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'dost_exam_result' grade (1) led to decision (dost_exam_result > 0.50). Branch: False\n",
      "  - Node 2: Student's 'Average grade' grade (87) led to decision (Average grade <= 89.50). Branch: True\n",
      "\n",
      "Program: Spfl - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (87) led to decision (Average grade <= 89.50). Branch: True\n",
      "\n",
      "Program: Sptve - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (87) led to decision (Average grade <= 89.50). Branch: True\n",
      "  - Final Node (Leaf): This path leads to a prediction of 0 for sptve.\n",
      "    (This node contains 214 samples, with 1.0 samples of class 0 and 0.0 samples of class 1)\n",
      "\n",
      "--- Summary Program Recommendations ---\n",
      "- Hetero: Eligible\n",
      "- Top 5: Eligible\n",
      "- Ste: Not Eligible\n",
      "- Spfl: Not Eligible\n",
      "- Sptve: Not Eligible\n"
     ]
    }
   ],
   "source": [
    "# Example: Make predictions for a new student\n",
    "# (Keep your new_student_data definition as is)\n",
    "\n",
    "new_student_data = pd.DataFrame([[1, 90, 85, 92, 88, 80, 85, 90, 82, 87]],\n",
    "                                columns=X.columns)\n",
    "\n",
    "print(\"\\nNew Student Data:\")\n",
    "print(new_student_data)\n",
    "\n",
    "recommended_programs = {}\n",
    "print(\"\\n--- Detailed Program Recommendations and Explanations ---\")\n",
    "for label, model in models.items():\n",
    "    prediction = model.predict(new_student_data)[0]\n",
    "    status = \"Eligible\" if prediction == 1 else \"Not Eligible\"\n",
    "    recommended_programs[label] = status\n",
    "\n",
    "    print(f\"\\nProgram: {label.replace('_', ' ').title()} - Status: {status}\")\n",
    "    print(\"Decision Path Explanation:\")\n",
    "\n",
    "    # Get the decision path for the new student\n",
    "    # This returns the indices of the nodes in the tree that the sample traverses\n",
    "    node_indicator = model.decision_path(new_student_data)\n",
    "    leaf_id = model.apply(new_student_data) # Get the leaf node ID\n",
    "\n",
    "    # Iterate through the nodes in the decision path\n",
    "    # The decision_path returns a sparse matrix, so we need to convert it to an array\n",
    "    path_nodes = node_indicator.indices[node_indicator.indptr[0]:node_indicator.indptr[1]]\n",
    "\n",
    "    # Get feature names for better readability\n",
    "    feature_names = X.columns.tolist()\n",
    "\n",
    "    for i, node_id in enumerate(path_nodes):\n",
    "        # If it's not the leaf node, it's a decision node\n",
    "        if node_id != leaf_id[0]:\n",
    "            feature = feature_names[model.tree_.feature[node_id]]\n",
    "            threshold = model.tree_.threshold[node_id]\n",
    "            value = new_student_data[feature].iloc[0] # Get the student's value for this feature\n",
    "\n",
    "            # Determine if the condition was true or false\n",
    "            if value <= threshold:\n",
    "                decision = f\"({feature} <= {threshold:.2f})\"\n",
    "                branch = \"True\"\n",
    "            else:\n",
    "                decision = f\"({feature} > {threshold:.2f})\"\n",
    "                branch = \"False\"\n",
    "\n",
    "            print(f\"  - Node {i+1}: Student's '{feature}' grade ({value}) led to decision {decision}. Branch: {branch}\")\n",
    "        else:\n",
    "            # This is the leaf node, which contains the final prediction\n",
    "            class_value = model.tree_.value[node_id][0][0] # Get the class value (0 or 1)\n",
    "            # The 'value' in the leaf node represents the counts of samples for each class\n",
    "            # For a binary classifier, it's usually [count_class_0, count_class_1]\n",
    "            # We want the class that has the higher count, which is implicitly the prediction.\n",
    "            # The prediction itself is already stored in 'prediction' variable.\n",
    "            counts = model.tree_.value[node_id][0]\n",
    "num_samples = model.tree_.n_node_samples[node_id]\n",
    "\n",
    "if len(counts) == 1:\n",
    "    # Only one class present in this leaf\n",
    "    class_0_count = counts[0]\n",
    "    class_1_count = 0\n",
    "else:\n",
    "    class_0_count = counts[0]\n",
    "    class_1_count = counts[1]\n",
    "\n",
    "print(f\"  - Final Node (Leaf): This path leads to a prediction of {prediction} for {label}.\")\n",
    "print(f\"    (This node contains {num_samples} samples, with {class_0_count} samples of class 0 and {class_1_count} samples of class 1)\")\n",
    "\n",
    "\n",
    "\n",
    "# Print the summary recommendations again\n",
    "print(\"\\n--- Summary Program Recommendations ---\")\n",
    "for program, status in recommended_programs.items():\n",
    "    print(f\"- {program.replace('_', ' ').title()}: {status}\")\n",
    "\n",
    "# Optional: Visualize one of the trees (e.g., for 'top 5')\n",
    "# This can be very large for deep trees, so use with caution.\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plot_tree(models['top 5'], feature_names=X.columns, class_names=['Not Eligible', 'Eligible'], filled=True, rounded=True)\n",
    "# plt.title(\"Decision Tree for 'top 5' Program Eligibility\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a18eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Student Data:\n",
      "   dost_exam_result  filipino grade  English grade  mathematics grade  \\\n",
      "0                 0              78             75                 82   \n",
      "\n",
      "   science grade  araling panlipunan grade  Edukasyon sa pagpapakatao grade  \\\n",
      "0             80                        80                               75   \n",
      "\n",
      "   Edukasyong panglipunan at pangkabuhayan grade  MAPEH grade  Average grade  \n",
      "0                                             79           78             79  \n",
      "\n",
      "--- Detailed Program Recommendations and Explanations ---\n",
      "\n",
      "Program: Hetero - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "\n",
      "Program: Top 5 - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (79) led to decision (Average grade <= 84.50). Branch: True\n",
      "\n",
      "Program: Ste - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'dost_exam_result' grade (0) led to decision (dost_exam_result <= 0.50). Branch: True\n",
      "\n",
      "Program: Spfl - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (79) led to decision (Average grade <= 89.50). Branch: True\n",
      "\n",
      "Program: Sptve - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (79) led to decision (Average grade <= 89.50). Branch: True\n",
      "  - Final Node (Leaf): This path leads to a prediction of 0 for sptve.\n",
      "    (This node contains 214 samples, with 1.0 samples of class 0 and 0.0 samples of class 1)\n",
      "\n",
      "--- Summary Program Recommendations ---\n",
      "- Hetero: Eligible\n",
      "- Top 5: Not Eligible\n",
      "- Ste: Not Eligible\n",
      "- Spfl: Not Eligible\n",
      "- Sptve: Not Eligible\n"
     ]
    }
   ],
   "source": [
    "# Example: Make predictions for a new student\n",
    "# (Keep your new_student_data definition as is)\n",
    "\n",
    "new_student_data = pd.DataFrame([[0, 78, 75, 82, 80, 80, 75, 79, 78, 79]],\n",
    "                                columns=X.columns)\n",
    "\n",
    "print(\"\\nNew Student Data:\")\n",
    "print(new_student_data)\n",
    "\n",
    "recommended_programs = {}\n",
    "print(\"\\n--- Detailed Program Recommendations and Explanations ---\")\n",
    "for label, model in models.items():\n",
    "    prediction = model.predict(new_student_data)[0]\n",
    "    status = \"Eligible\" if prediction == 1 else \"Not Eligible\"\n",
    "    recommended_programs[label] = status\n",
    "\n",
    "    print(f\"\\nProgram: {label.replace('_', ' ').title()} - Status: {status}\")\n",
    "    print(\"Decision Path Explanation:\")\n",
    "\n",
    "    # Get the decision path for the new student\n",
    "    # This returns the indices of the nodes in the tree that the sample traverses\n",
    "    node_indicator = model.decision_path(new_student_data)\n",
    "    leaf_id = model.apply(new_student_data) # Get the leaf node ID\n",
    "\n",
    "    # Iterate through the nodes in the decision path\n",
    "    # The decision_path returns a sparse matrix, so we need to convert it to an array\n",
    "    path_nodes = node_indicator.indices[node_indicator.indptr[0]:node_indicator.indptr[1]]\n",
    "\n",
    "    # Get feature names for better readability\n",
    "    feature_names = X.columns.tolist()\n",
    "\n",
    "    for i, node_id in enumerate(path_nodes):\n",
    "        # If it's not the leaf node, it's a decision node\n",
    "        if node_id != leaf_id[0]:\n",
    "            feature = feature_names[model.tree_.feature[node_id]]\n",
    "            threshold = model.tree_.threshold[node_id]\n",
    "            value = new_student_data[feature].iloc[0] # Get the student's value for this feature\n",
    "\n",
    "            # Determine if the condition was true or false\n",
    "            if value <= threshold:\n",
    "                decision = f\"({feature} <= {threshold:.2f})\"\n",
    "                branch = \"True\"\n",
    "            else:\n",
    "                decision = f\"({feature} > {threshold:.2f})\"\n",
    "                branch = \"False\"\n",
    "\n",
    "            print(f\"  - Node {i+1}: Student's '{feature}' grade ({value}) led to decision {decision}. Branch: {branch}\")\n",
    "        else:\n",
    "            # This is the leaf node, which contains the final prediction\n",
    "            class_value = model.tree_.value[node_id][0][0] # Get the class value (0 or 1)\n",
    "            # The 'value' in the leaf node represents the counts of samples for each class\n",
    "            # For a binary classifier, it's usually [count_class_0, count_class_1]\n",
    "            # We want the class that has the higher count, which is implicitly the prediction.\n",
    "            # The prediction itself is already stored in 'prediction' variable.\n",
    "            counts = model.tree_.value[node_id][0]\n",
    "num_samples = model.tree_.n_node_samples[node_id]\n",
    "\n",
    "if len(counts) == 1:\n",
    "    # Only one class present in this leaf\n",
    "    class_0_count = counts[0]\n",
    "    class_1_count = 0\n",
    "else:\n",
    "    class_0_count = counts[0]\n",
    "    class_1_count = counts[1]\n",
    "\n",
    "print(f\"  - Final Node (Leaf): This path leads to a prediction of {prediction} for {label}.\")\n",
    "print(f\"    (This node contains {num_samples} samples, with {class_0_count} samples of class 0 and {class_1_count} samples of class 1)\")\n",
    "\n",
    "\n",
    "\n",
    "# Print the summary recommendations again\n",
    "print(\"\\n--- Summary Program Recommendations ---\")\n",
    "for program, status in recommended_programs.items():\n",
    "    print(f\"- {program.replace('_', ' ').title()}: {status}\")\n",
    "\n",
    "# Optional: Visualize one of the trees (e.g., for 'top 5')\n",
    "# This can be very large for deep trees, so use with caution.\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plot_tree(models['top 5'], feature_names=X.columns, class_names=['Not Eligible', 'Eligible'], filled=True, rounded=True)\n",
    "# plt.title(\"Decision Tree for 'top 5' Program Eligibility\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c24b2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Student Data:\n",
      "   dost_exam_result  filipino grade  English grade  mathematics grade  \\\n",
      "0                 0              90             95                 92   \n",
      "\n",
      "   science grade  araling panlipunan grade  Edukasyon sa pagpapakatao grade  \\\n",
      "0             90                        90                               89   \n",
      "\n",
      "   Edukasyong panglipunan at pangkabuhayan grade  MAPEH grade  Average grade  \n",
      "0                                             94           93             93  \n",
      "\n",
      "--- Detailed Program Recommendations and Explanations ---\n",
      "\n",
      "Program: Hetero - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "\n",
      "Program: Top 5 - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (93) led to decision (Average grade > 84.50). Branch: False\n",
      "  - Node 2: Student's 'Edukasyong panglipunan at pangkabuhayan grade' grade (94) led to decision (Edukasyong panglipunan at pangkabuhayan grade > 76.50). Branch: False\n",
      "  - Node 3: Student's 'filipino grade' grade (90) led to decision (filipino grade > 75.50). Branch: False\n",
      "\n",
      "Program: Ste - Status: Not Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'dost_exam_result' grade (0) led to decision (dost_exam_result <= 0.50). Branch: True\n",
      "\n",
      "Program: Spfl - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (93) led to decision (Average grade > 89.50). Branch: False\n",
      "\n",
      "Program: Sptve - Status: Eligible\n",
      "Decision Path Explanation:\n",
      "  - Node 1: Student's 'Average grade' grade (93) led to decision (Average grade > 89.50). Branch: False\n",
      "  - Final Node (Leaf): This path leads to a prediction of 1 for sptve.\n",
      "    (This node contains 330 samples, with 0.0 samples of class 0 and 1.0 samples of class 1)\n",
      "\n",
      "--- Summary Program Recommendations ---\n",
      "- Hetero: Eligible\n",
      "- Top 5: Eligible\n",
      "- Ste: Not Eligible\n",
      "- Spfl: Eligible\n",
      "- Sptve: Eligible\n"
     ]
    }
   ],
   "source": [
    "# Example: Make predictions for a new student\n",
    "# (Keep your new_student_data definition as is)\n",
    "\n",
    "new_student_data = pd.DataFrame([[0, 90, 95, 92, 90, 90, 89, 94, 93, 93]],\n",
    "                                columns=X.columns)\n",
    "\n",
    "print(\"\\nNew Student Data:\")\n",
    "print(new_student_data)\n",
    "\n",
    "recommended_programs = {}\n",
    "print(\"\\n--- Detailed Program Recommendations and Explanations ---\")\n",
    "for label, model in models.items():\n",
    "    prediction = model.predict(new_student_data)[0]\n",
    "    status = \"Eligible\" if prediction == 1 else \"Not Eligible\"\n",
    "    recommended_programs[label] = status\n",
    "\n",
    "    print(f\"\\nProgram: {label.replace('_', ' ').title()} - Status: {status}\")\n",
    "    print(\"Decision Path Explanation:\")\n",
    "\n",
    "    # Get the decision path for the new student\n",
    "    # This returns the indices of the nodes in the tree that the sample traverses\n",
    "    node_indicator = model.decision_path(new_student_data)\n",
    "    leaf_id = model.apply(new_student_data) # Get the leaf node ID\n",
    "\n",
    "    # Iterate through the nodes in the decision path\n",
    "    # The decision_path returns a sparse matrix, so we need to convert it to an array\n",
    "    path_nodes = node_indicator.indices[node_indicator.indptr[0]:node_indicator.indptr[1]]\n",
    "\n",
    "    # Get feature names for better readability\n",
    "    feature_names = X.columns.tolist()\n",
    "\n",
    "    for i, node_id in enumerate(path_nodes):\n",
    "        # If it's not the leaf node, it's a decision node\n",
    "        if node_id != leaf_id[0]:\n",
    "            feature = feature_names[model.tree_.feature[node_id]]\n",
    "            threshold = model.tree_.threshold[node_id]\n",
    "            value = new_student_data[feature].iloc[0] # Get the student's value for this feature\n",
    "\n",
    "            # Determine if the condition was true or false\n",
    "            if value <= threshold:\n",
    "                decision = f\"({feature} <= {threshold:.2f})\"\n",
    "                branch = \"True\"\n",
    "            else:\n",
    "                decision = f\"({feature} > {threshold:.2f})\"\n",
    "                branch = \"False\"\n",
    "\n",
    "            print(f\"  - Node {i+1}: Student's '{feature}' grade ({value}) led to decision {decision}. Branch: {branch}\")\n",
    "        else:\n",
    "            # This is the leaf node, which contains the final prediction\n",
    "            class_value = model.tree_.value[node_id][0][0] # Get the class value (0 or 1)\n",
    "            # The 'value' in the leaf node represents the counts of samples for each class\n",
    "            # For a binary classifier, it's usually [count_class_0, count_class_1]\n",
    "            # We want the class that has the higher count, which is implicitly the prediction.\n",
    "            # The prediction itself is already stored in 'prediction' variable.\n",
    "            counts = model.tree_.value[node_id][0]\n",
    "num_samples = model.tree_.n_node_samples[node_id]\n",
    "\n",
    "if len(counts) == 1:\n",
    "    # Only one class present in this leaf\n",
    "    class_0_count = counts[0]\n",
    "    class_1_count = 0\n",
    "else:\n",
    "    class_0_count = counts[0]\n",
    "    class_1_count = counts[1]\n",
    "\n",
    "print(f\"  - Final Node (Leaf): This path leads to a prediction of {prediction} for {label}.\")\n",
    "print(f\"    (This node contains {num_samples} samples, with {class_0_count} samples of class 0 and {class_1_count} samples of class 1)\")\n",
    "\n",
    "\n",
    "\n",
    "# Print the summary recommendations again\n",
    "print(\"\\n--- Summary Program Recommendations ---\")\n",
    "for program, status in recommended_programs.items():\n",
    "    print(f\"- {program.replace('_', ' ').title()}: {status}\")\n",
    "\n",
    "# Optional: Visualize one of the trees (e.g., for 'top 5')\n",
    "# This can be very large for deep trees, so use with caution.\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plot_tree(models['top 5'], feature_names=X.columns, class_names=['Not Eligible', 'Eligible'], filled=True, rounded=True)\n",
    "# plt.title(\"Decision Tree for 'top 5' Program Eligibility\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8211abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming your decision tree model is named 'model' (or a dict of models)\n",
    "# For example, if you have multiple models in a dict called 'models':\n",
    "with open('decision_tree_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "\n",
    "# Or if you have a single model:\n",
    "# with open('decision_tree_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
